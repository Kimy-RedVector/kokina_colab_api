{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "iLsO_riJrAEl",
        "QAvV1XNM3TxR"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Kokina API üîÆ**\n",
        "\n",
        "<img src=\"https://count.getloli.com/get/@:ncpt-colab?theme=rule34\" height=\"90px\" alt=\"counted since: May 14\"/>\n",
        "\n",
        "ncpt source"
      ],
      "metadata": {
        "id": "mgKX41doZJ3u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# **Colab Mobile Keep Alive**\n",
        "\n",
        "*Run this cell to keep the tab alive in mobile (before running the start cell)*"
      ],
      "metadata": {
        "id": "iLsO_riJrAEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Run this cell to keep the tab alive in mobile (before running the start cell)\n",
        "\n",
        "%%html\n",
        "<b>Press play on the music player to keep the tab alive before running the start cell (Uses only 13MB of data)</b><br/>\n",
        "<audio src=\"https://raw.githubusercontent.com/KoboldAI/KoboldAI-Client/main/colab/silence.m4a\" controls>"
      ],
      "metadata": {
        "id": "ZIL7itnNaw5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Start**"
      ],
      "metadata": {
        "id": "P-gs46ksgoeb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Uvqba0yKW7U"
      },
      "outputs": [],
      "source": [
        "# **Useful Utilities (Optional)**\n",
        "# Dear Google, I love you! Please don't ban me from colab T_T\n",
        "\n",
        "from IPython.display import clear_output, display, HTML\n",
        "import os\n",
        "import time\n",
        "from datetime import timedelta\n",
        "from google.colab import drive\n",
        "from IPython.utils import capture\n",
        "from subprocess import getoutput\n",
        "from urllib.parse import unquote\n",
        "from google.colab.output import eval_js\n",
        "%cd /content\n",
        "\n",
        "try:\n",
        "  start_colab\n",
        "except:\n",
        "  start_colab = int(time.time())-5\n",
        "\n",
        "print(\"\\033[96m\") #Cyan text\n",
        "# Check if gpu exist, stop if don't.\n",
        "try:\n",
        "  output\n",
        "except:\n",
        "  print('‚åö Checking GPU...', end='')\n",
        "  output = getoutput('nvidia-smi --query-gpu=gpu_name --format=csv')\n",
        "  if \"name\" in output:\n",
        "    gpu_name = output[5:]\n",
        "    print('\\r‚úÖ Current GPU:', gpu_name, flush=True)\n",
        "  else:\n",
        "    print('\\r\\033[91m‚ùé ERROR: No GPU detected. Please do step below to enable.\\n', flush=True)\n",
        "    display(HTML(\"<img src='https://i.ibb.co/HC9KH17/NVIDIA-Share-23-01-02-173037.png' width='800px'/>\"))\n",
        "    print('\\033[91m\\nIf it says \"Cannot connect to GPU backend\", meaning you\\'ve either reached free usage limit. OR there\\'s no gpu available.\\n\\nDon\\'t mind me... I\\'m destroying your current session for your own good...')\n",
        "    display(HTML(\"<img src='https://media.tenor.com/E9omRGF7x0AAAAAC/hitori-gotou-bocchi-rock.gif' width='500px'/>\"))\n",
        "    time.sleep(5)\n",
        "    from google.colab import runtime\n",
        "    runtime.unassign()\n",
        "\n",
        "# [ALL PARAMS]-----------------------------------------------\n",
        "\n",
        "latest_webui = False\n",
        "latest_extensions = True\n",
        "branch = \"master\"\n",
        "sdxl_patch = False\n",
        "\n",
        "\n",
        "output_to_drive = False\n",
        "configs_in_drive = False\n",
        "fast_start = False\n",
        "auto_vae = False\n",
        "no_custom_theme = False\n",
        "merge_in_vram = False\n",
        "load_in_vram = False\n",
        "ram_patch_for_sd2 = False\n",
        "dpmpp_v2 = False\n",
        "krita_paint_ext = False\n",
        "verbose_download = False\n",
        "commandline_arguments = \"--enable-insecure-extension-access --share --disable-safe-unpickle --theme dark --no-hashing --xformers\"\n",
        "commit_hash = \"\"\n",
        "ngrok_token  = \"\"\n",
        "ngrok_region = \"jp\"\n",
        "ngrok_auto_save_load = False\n",
        "alternative_tunnels = False\n",
        "with_bore = False\n",
        "\n",
        "optional_huggingface_token=\"\"\n",
        "model_url = \"\"\n",
        "# waifu_diffusion_AES = False #@param{type:\"boolean\"}\n",
        "# waifu_diffusion = False #@param{type:\"boolean\"}\n",
        "waifu_diffusion = \"none\"\n",
        "# anything_v3 = False\n",
        "anything_v4_5 = False\n",
        "anylora = False\n",
        "amedira = False\n",
        "awooooooo = False\n",
        "gishiki_v1_1 = True\n",
        "something_v2_2 = False\n",
        "anything_vae = False\n",
        "blessed2_vae = True\n",
        "wd_vae = False\n",
        "sd_vae = False\n",
        "controlnet = \"v1.1\"\n",
        "null_model = False\n",
        "custom_urls = \"\"\n",
        "\n",
        "# CONFIG DIR (not recommended to change unless you know what you're doing) modules/sd_models.py\n",
        "destination_dir = \"/content/.downloaded/\"\n",
        "config_dir=\"/content/sdw/config.json\"\n",
        "models_dir = \"/content/sdw/models/Stable-diffusion/\"\n",
        "vaes_dir = \"/content/sdw/models/VAE/\"\n",
        "hypernetworks_dir = \"/content/sdw/models/hypernetworks/\"\n",
        "embeddings_dir = \"/content/sdw/embeddings/\"\n",
        "loras_dir = \"/content/sdw/models/Lora/\"\n",
        "# lycoris_dir = \"/content/sdw/models/LyCORIS/\"\n",
        "patches_dir = \"/content/patches/\"\n",
        "extensions_dir = \"/content/sdw/extensions/\"\n",
        "control_dir = \"/content/sdw/models/ControlNet/\"\n",
        "drive_config_dir = \"/content/gdrive/MyDrive/WebUI/configs/\"\n",
        "sam_dir = \"/content/sdw/models/sam/\"\n",
        "\n",
        "# -----------------------------------------------\n",
        "\n",
        "# Append models to model_url\n",
        "model_url+=custom_urls+\", \" if custom_urls else \"\"\n",
        "# if anything_v3:\n",
        "#   model_url+=\"https://huggingface.co/NoCrypt/safetensor_models/resolve/main/Anything-V3.0-pruned-fp32.safetensors, \"\n",
        "\n",
        "if anylora:\n",
        "  model_url+=\"https://huggingface.co/Lykon/AnyLoRA/resolve/main/AnyLoRA_noVae_fp16-pruned.safetensors, \"\n",
        "if amedira:\n",
        "  model_url+=\"https://huggingface.co/AshtakaOOf/Amedira/resolve/main/Amedira-bV.safetensors, \"\n",
        "if anything_v4_5:\n",
        "  model_url+=\"https://huggingface.co/ckpt/anything-v4.0/resolve/main/anything-v4.5-pruned.safetensors, \"\n",
        "if gishiki_v1_1:\n",
        "  model_url+=\"https://huggingface.co/Aotsuyu/Gishiki/resolve/main/Gishikiv1.1.safetensors, \"\n",
        "if something_v2_2:\n",
        "  model_url+=\"https://huggingface.co/NoCrypt/SomethingV2_2/resolve/main/SomethingV2_2.safetensors, \"\n",
        "if waifu_diffusion == \"radiance\":\n",
        "  model_url+=\"https://huggingface.co/waifu-diffusion/wd-1-5-beta3/resolve/main/wd-radiance-fp16.safetensors, \"\n",
        "if waifu_diffusion == \"ink\":\n",
        "  model_url+=\"https://huggingface.co/waifu-diffusion/wd-1-5-beta3/resolve/main/wd-ink-fp16.safetensors, \"\n",
        "if waifu_diffusion == \"mofu\": #mofu!\n",
        "  model_url+=\"https://huggingface.co/waifu-diffusion/wd-1-5-beta3/resolve/main/wd-mofu-fp16.safetensors, \"\n",
        "if waifu_diffusion == \"illusion\":\n",
        "  model_url+=\"https://huggingface.co/waifu-diffusion/wd-1-5-beta3/resolve/main/wd-illusion-fp16.safetensors, \"\n",
        "if awooooooo:\n",
        "  model_url+=\"https://huggingface.co/yoinked/merges/resolve/main/awoo/awooooooo.safetensors, \"\n",
        "\n",
        "if anything_vae or anything_v4_5 or anylora:\n",
        "  model_url+=\" https://huggingface.co/NoCrypt/resources/resolve/main/VAE/any.vae.safetensors, \"\n",
        "if blessed2_vae:\n",
        "  model_url+=\"https://huggingface.co/NoCrypt/resources/resolve/main/VAE/blessed2.vae.safetensors, \"\n",
        "if wd_vae or waifu_diffusion!=\"none\":\n",
        "  model_url+=\"https://huggingface.co/NoCrypt/resources/resolve/main/VAE/wd.vae.safetensors, \"\n",
        "if sd_vae:\n",
        "  model_url+=\"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors, \"\n",
        "if controlnet == \"v1.0\":\n",
        "  model_url+=\"https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_canny-fp16.safetensors, https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_depth-fp16.safetensors, https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_hed-fp16.safetensors, https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_mlsd-fp16.safetensors, https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_normal-fp16.safetensors, https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_openpose-fp16.safetensors, https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_scribble-fp16.safetensors, https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_seg-fp16.safetensors, \"\n",
        "if controlnet == \"v1.0-diff\":\n",
        "  model_url+=\"https://huggingface.co/kohya-ss/ControlNet-diff-modules/resolve/main/diff_control_sd15_canny_fp16.safetensors, https://huggingface.co/kohya-ss/ControlNet-diff-modules/resolve/main/diff_control_sd15_depth_fp16.safetensors, https://huggingface.co/kohya-ss/ControlNet-diff-modules/resolve/main/diff_control_sd15_hed_fp16.safetensors, https://huggingface.co/kohya-ss/ControlNet-diff-modules/resolve/main/diff_control_sd15_mlsd_fp16.safetensors, https://huggingface.co/kohya-ss/ControlNet-diff-modules/resolve/main/diff_control_sd15_normal_fp16.safetensors, https://huggingface.co/kohya-ss/ControlNet-diff-modules/resolve/main/diff_control_sd15_openpose_fp16.safetensors, https://huggingface.co/kohya-ss/ControlNet-diff-modules/resolve/main/diff_control_sd15_scribble_fp16.safetensors, https://huggingface.co/kohya-ss/ControlNet-diff-modules/resolve/main/diff_control_sd15_seg_fp16.safetensors, \"\n",
        "if controlnet == \"t2i\":\n",
        "  model_url+=\"https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/t2iadapter_canny-fp16.safetensors, https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/t2iadapter_color-fp16.safetensors, https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/t2iadapter_depth-fp16.safetensors, https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/t2iadapter_keypose-fp16.safetensors, https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/t2iadapter_openpose-fp16.safetensors, https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/t2iadapter_seg-fp16.safetensors, https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/t2iadapter_sketch-fp16.safetensors, https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/t2iadapter_style-fp16.safetensors,\"\n",
        "if controlnet == \"v1.1\":\n",
        "  model_url+=\"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11e_sd15_ip2p_fp16.safetensors, control:https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11e_sd15_ip2p_fp16.yaml, https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11e_sd15_shuffle_fp16.safetensors, control:https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11e_sd15_shuffle_fp16.yaml, https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11f1e_sd15_tile_fp16.safetensors, control:https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11f1e_sd15_tile_fp16.yaml, https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11f1p_sd15_depth_fp16.safetensors, control:https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11f1p_sd15_depth_fp16.yaml, https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_canny_fp16.safetensors, control:https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_canny_fp16.yaml, https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_depth_fp16.safetensors, control:https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_depth_fp16.yaml, https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_inpaint_fp16.safetensors, control:https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_inpaint_fp16.yaml, https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_lineart_fp16.safetensors, control:https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_lineart_fp16.yaml, https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_mlsd_fp16.safetensors, control:https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_mlsd_fp16.yaml, https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_normalbae_fp16.safetensors, control:https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_normalbae_fp16.yaml, https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_openpose_fp16.safetensors, control:https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_openpose_fp16.yaml, https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_scribble_fp16.safetensors, control:https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_scribble_fp16.yaml, https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_seg_fp16.safetensors, control:https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_seg_fp16.yaml, https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_softedge_fp16.safetensors, control:https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_softedge_fp16.yaml, https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15s2_lineart_anime_fp16.safetensors, control:https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15s2_lineart_anime_fp16.yaml, https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11u_sd15_tile_fp16.safetensors, control:https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11u_sd15_tile_fp16.yaml, \"\n",
        "\n",
        "# Image outputs to drive (part 1)\n",
        "if output_to_drive or configs_in_drive:\n",
        "  if not os.path.exists('/content/gdrive'):\n",
        "    drive.mount('/content/gdrive')\n",
        "\n",
        "# Unpack Repo, Dependencies, Caches\n",
        "if not os.path.exists(\"/content/sdw\"):\n",
        "  start_install = int(time.time())\n",
        "\n",
        "  # [!] Copy Warning ‚ö†Ô∏è --------------------------------------\n",
        "  # By removing these, you understand that updates will most likely breaks some stuff.\n",
        "  # I suggest you to use \"permanent\" link for repo, deps, and cache. This will prevent this colab from breaking when I update it.\n",
        "  # How to get permanent link? Go to a commit in my repo (https://huggingface.co/NoCrypt/fast-repo/commits/main) then click browse file.\n",
        "  # Then copy repo file link from that commit, it should be something like this: https://huggingface.co/NoCrypt/fast-repo/resolve/faa7a6c0a7d4d456415326285446225d12d0d426/repo.tar.lz4\n",
        "  # Replace the repo link below (in aria2c) to permanent link\n",
        "  # -----------------------------------------------------------\n",
        "  with capture.capture_output() as cap:\n",
        "    !pip install -q ipynbname\n",
        "  from ipynbname import name as nnb\n",
        "  if not nnb().split('=')[1].startswith(\"1wEa-tS10h4LlDykd87TF5zzpXIIQoCmq\"):\n",
        "    display(HTML(\"\"\"\n",
        "      <p style=\"color:red;font-size:25px\"><u> üíÄ Colab copy detected üíÄ</u></p>\n",
        "      <p style=\"font-size:20px\">Please keep your copy up-to-date, do not report any bugs to NoCrypt<br/><br/></p>\n",
        "      <img src=\"https://i.ibb.co/2kV0btp/download-74.png\"/><br/><br/>\n",
        "      <p style=\"font-size:20px\">Please keep your copy up-to-date, do not report any bugs to NoCrypt</p>\n",
        "      <p style=\"font-size:20px\">P.s. Feel free to remove this warning! I've included a note on how to prevent colab from breaking in the code </p>\n",
        "    \"\"\"))\n",
        "    time.sleep(10)\n",
        "  # ------------------------------------ Feel free to remove! Don't forget to read notes above ‚úåÔ∏è\n",
        "\n",
        "\n",
        "  print(\"üöÄ Unpacking... Please do not stop this process at all cost...\", end='')\n",
        "  with capture.capture_output() as cap:\n",
        "    # !rm -rf /usr/local/lib/python3.10/dist-packages/scipy /usr/local/lib/python3.10/dist-packages/scipy-*.dist-info/ /usr/local/lib/python3.10/dist-packages/scipy.libs\n",
        "    # !apt install -qq libunwind8-dev\n",
        "    !wget https://huggingface.co/NoCrypt/fast-repo/resolve/main/ubuntu_deps.zip ; unzip ubuntu_deps.zip -d ./deps ; dpkg -i ./deps/* ; rm -rf ubuntu_deps.zip /content/deps/\n",
        "    # !apt install liblz4-tool aria2\n",
        "    # !pip uninstall -q -y huggingface_hub\n",
        "    # !{'curl -LO https://github.com/BurntSushi/ripgrep/releases/download/13.0.0/ripgrep_13.0.0_amd64.deb && dpkg -i ripgrep_13.0.0_amd64.deb && rm -rf ripgrep_13.0.0_amd64.deb'}\n",
        "\n",
        "    # !aria2c --summary-interval=10 -c -x 16 -k 1M -s 16 -d /content -Z \\\n",
        "    #   https://huggingface.co/NoCrypt/fast-repo/resolve/main/dep.tar.lz4 \\\n",
        "    #   https://huggingface.co/NoCrypt/fast-repo/resolve/main/repo.tar.lz4 \\\n",
        "    #   https://huggingface.co/NoCrypt/fast-repo/resolve/main/cache.tar.lz4\n",
        "\n",
        "    # !aria2c -d /content -o dep.tar.lz4 --summary-interval=10 -c -x 16 -k 1M -s 16 https://huggingface.co/NoCrypt/fast-repo/resolve/main/dep.tar.lz4\n",
        "    # !aria2c -d /content -o repo.tar.lz4 --summary-interval=10 -c -x 16 -k 1M -s 16 https://huggingface.co/NoCrypt/fast-repo/resolve/main/repo.tar.lz4\n",
        "    # !aria2c -d /content -o cache.tar.lz4 --summary-interval=10 -c -x 16 -k 1M -s 16 https://huggingface.co/NoCrypt/fast-repo/resolve/main/cache.tar.lz4\n",
        "\n",
        "    !echo -e \"https://huggingface.co/NoCrypt/fast-repo/resolve/main/dep.tar.lz4\\n\\tout=dep.tar.lz4\\nhttps://huggingface.co/NoCrypt/fast-repo/resolve/main/repo.tar.lz4\\n\\tout=repo.tar.lz4\\nhttps://huggingface.co/NoCrypt/fast-repo/resolve/main/cache.tar.lz4\\n\\tout=cache.tar.lz4\\n\" \\\n",
        "      | aria2c -i- -j5 -x16 -s16 -k1M -c\n",
        "\n",
        "    !tar -xI lz4 -f dep.tar.lz4 --overwrite-dir --directory=/usr/local/lib/python3.10/dist-packages/ #(manual dir)\n",
        "    !tar -xI lz4 -f repo.tar.lz4 --directory=/ #/content/sdw/ (auto dir)\n",
        "    !tar -xI lz4 -f cache.tar.lz4 --directory=/ #/root/.cache/huggingface (auto dir)\n",
        "\n",
        "    !rm -rf /content/dep.tar.lz4 /content/repo.tar.lz4 /content/cache.tar.lz4\n",
        "    os.environ[\"SAFETENSORS_FAST_GPU\"]='1'\n",
        "    os.environ[\"CUDA_MODULE_LOADING\"]=\"LAZY\"\n",
        "    os.environ[\"colab_url\"] = eval_js(\"google.colab.kernel.proxyPort(7860, {'cache': false})\")\n",
        "    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
        "    # %env PYTHONDONTWRITEBYTECODE=1\n",
        "    os.environ[\"TCMALLOC_AGGRESSIVE_DECOMMIT\"] = \"t\"\n",
        "\n",
        "    !rm /content/sdw/extensions/tunnels/id_rsa.pub\n",
        "    !rm /content/sdw/extensions/tunnels/id_rsa\n",
        "\n",
        "    # os.environ['PYTORCH_CUDA_ALLOC_CONF'] = \"garbage_collection_threshold:0.9,max_split_size_mb:512\"\n",
        "    # !apt -y update -qq\n",
        "\n",
        "    !wget https://github.com/camenduru/gperftools/releases/download/v1.0/libtcmalloc_minimal.so.4 -O /content/libtcmalloc_minimal.so.4 -c\n",
        "    %env LD_PRELOAD=/content/libtcmalloc_minimal.so.4\n",
        "\n",
        "    !pip install https://download.pytorch.org/whl/cu121/xformers-0.0.22.post4-cp310-cp310-manylinux2014_x86_64.whl#sha256=7075114dbf698b609b599f0d35032c0b2f9a389751e8bbf4dd3c628376b0dd9c\n",
        "\n",
        "    del cap\n",
        "  if not os.path.exists(hypernetworks_dir):\n",
        "    os.makedirs(hypernetworks_dir)\n",
        "  # if not 'T4' in gpu_name:  # [For colab makers out there, facebook's xformers pypi already support almost all gpu now]\n",
        "  #   !pip uninstall -y xformers\n",
        "  install_time = timedelta(seconds=time.time()-start_install)\n",
        "  print(\"\\rüöÄ Finished unpacking. Took\",\"%02d:%02d:%02d ‚ö°\\n\" % (install_time.seconds / 3600, (install_time.seconds / 60) % 60, install_time.seconds % 60), end='', flush=True)\n",
        "  # Colab ü§ù Gradio (Colab timer integration for gradio)\n",
        "  !echo -n {start_colab} > /content/sdw/static/colabTimer.txt\n",
        "  print(\"ü§ù Colab timer integration complete! You can see your colab time inside webui.\")\n",
        "\n",
        "  # Update using git pull\n",
        "  if latest_webui:\n",
        "    !git config --global user.email \"you@example.com\"\n",
        "    !git config --global user.name \"Your Name\"\n",
        "    print('‚åö Pulling latest changes...', end=\"\")\n",
        "    with capture.capture_output() as cap:\n",
        "      %cd /content/sdw\n",
        "      !git restore .\n",
        "      !git pull -X theirs --rebase --autostash\n",
        "      del cap\n",
        "    print('\\rü™Ñ \\033[96mYou are currently using latest version of webui. Please use commit_hash if there is error', flush=True)\n",
        "\n",
        "  if branch != \"master\":\n",
        "    print(f'‚åö Changing branch to {branch}', end=\"\")\n",
        "    with capture.capture_output() as cap:\n",
        "      !git restore .\n",
        "      !git checkout {branch}\n",
        "      !git pull\n",
        "    print(f'\\rü™Ñ \\033[96mYou are currently using {branch} branch of webui', flush=True)\n",
        "\n",
        "  # 3.32.xx sucks! Pngwn made some changes on 3.33.1 and it's 300% better\n",
        "  !sed -i 's@gradio==3.32.*@gradio==3.33.1@' /content/sdw/requirements_versions.txt\n",
        "\n",
        "  # Update extensions\n",
        "  if latest_extensions:\n",
        "    print('‚åö Updating extensions (might take a while)...', end=\"\")\n",
        "    with capture.capture_output() as cap:\n",
        "      !{'for dir in /content/sdw/extensions/*/; do cd \"$dir\" && git fetch origin && git pull; done'}\n",
        "    del cap\n",
        "    print('\\rü™Ñ \\033[96mInbuilt extensions are updated to its latest versions', flush=True)\n",
        "\n",
        "  !cd /content/sdw/repositories/stable-diffusion-stability-ai && git restore .\n",
        "  if sdxl_patch:\n",
        "    !sed -i -e '''/from modules import launch_utils/a\\import os''' /content/sdw/launch.py\n",
        "    !sed -i -e '''/        prepare_environment()/a\\        os.system\\(f\\\"\"\"sed -i -e ''\\\"s/dict()))/dict())).cuda()/g\\\"'' /content/sdw/repositories/stable-diffusion-stability-ai/ldm/util.py\"\"\")''' /content/sdw/launch.py\n",
        "\n",
        "else:\n",
        "  print(\"üöÄ Already unpacked... Skipping.\")\n",
        "  time_since_start = timedelta(seconds=time.time()-start_colab)\n",
        "  print(\"‚åö You've been running this colab for\",\"%02d:%02d:%02d\" % (time_since_start.seconds / 3600, (time_since_start.seconds / 60) % 60, time_since_start.seconds % 60))\n",
        "\n",
        "os.makedirs(patches_dir, exist_ok=True)\n",
        "# Revert changes using time-machine (git reset)\n",
        "if commit_hash:\n",
        "  print('‚åö Activating time machine...', end=\"\")\n",
        "  with capture.capture_output() as cap:\n",
        "    %cd /content/sdw\n",
        "    !git config --global user.email \"you@example.com\"\n",
        "    !git config --global user.name \"Your Name\"\n",
        "    # !git stash\n",
        "    !git reset --hard {commit_hash}\n",
        "    # !git stash apply\n",
        "    # !rm -rf /content/sdw/embeddings/*\n",
        "    del cap\n",
        "  print('\\r‚åö Time machine activated, you\\'re on commit', commit_hash, flush=True)\n",
        "  # print('‚úåÔ∏è Embeddings have been deleted for time machine support')\n",
        "\n",
        "# Colab patches for quality of life improvements\n",
        "with capture.capture_output() as cap:\n",
        "  !wget https://gist.github.com/NoCrypt/6e7331eda3d670c2156852ae5e300a42/raw/e52dac97fcabcb054b5737e0c5188cbc600c6582/DPMPP_2M_V2.patch -P {patches_dir}  -c\n",
        "  !wget https://gist.github.com/NoCrypt/6e7331eda3d670c2156852ae5e300a42/raw/e52dac97fcabcb054b5737e0c5188cbc600c6582/idgaf_about_git_ext.patch -P {patches_dir}  -c\n",
        "  !wget https://gist.github.com/NoCrypt/6e7331eda3d670c2156852ae5e300a42/raw/e52dac97fcabcb054b5737e0c5188cbc600c6582/sd-lowram.patch -P {patches_dir}  -c\n",
        "  if ram_patch_for_sd2:\n",
        "    pass # no needed\n",
        "  #   !cd /content/sdw/ && git apply --ignore-whitespace {patches_dir}/sd-lowram.patch\n",
        "  # else:\n",
        "  #   !cd /content/sdw/ && git apply --ignore-whitespace -R {patches_dir}/sd-lowram.patch\n",
        "\n",
        "\n",
        "  if dpmpp_v2:\n",
        "    !cd /content/sdw/ && git apply --ignore-whitespace {patches_dir}/DPMPP_2M_V2.patch\n",
        "  else:\n",
        "    !cd /content/sdw/ && git apply --ignore-whitespace -R {patches_dir}/DPMPP_2M_V2.patch\n",
        "\n",
        "  # IGAF, get lost git ext checker thingy\n",
        "  # !cd /content/sdw/ && git apply --ignore-whitespace {patches_dir}/idgaf_about_git_ext.patch\n",
        "\n",
        "  # Colab Optimizations modified to load_in_vram\n",
        "  if load_in_vram:\n",
        "    commandline_arguments += ' --lowram '\n",
        "\n",
        "  # Merge in vram: self-explainotory\n",
        "  if merge_in_vram:\n",
        "    !sed -i \"s@'cpu'@'cuda'@\" /content/sdw/modules/extras.py\n",
        "  else:\n",
        "    !sed -i \"s@'cuda'@'cpu'@\" /content/sdw/modules/extras.py\n",
        "\n",
        "  # Remove custom theme (since it's not for everyone)\n",
        "  if no_custom_theme:\n",
        "    !sed -i 's@\"gradio_theme\":.*@\"gradio_theme\": \"Default\",@' {config_dir}\n",
        "  else:\n",
        "    !sed -i 's@\"gradio_theme\":.*@\"gradio_theme\": \"NoCrypt/miku\",@' {config_dir}\n",
        "\n",
        "# Ngrok stuff goes here\n",
        "if ngrok_token or ngrok_auto_save_load:\n",
        "  if ngrok_auto_save_load:\n",
        "    if not os.path.exists('/content/gdrive'):\n",
        "      drive.mount('/content/gdrive')\n",
        "    if ngrok_token:\n",
        "      if not os.path.exists(\"/content/gdrive/MyDrive/WebUI/ngrokToken.txt\"):\n",
        "        !mkdir -p /content/gdrive/MyDrive/WebUI/\n",
        "        !touch /content/gdrive/MyDrive/WebUI/ngrokToken.txt\n",
        "      f = open(\"/content/gdrive/MyDrive/WebUI/ngrokToken.txt\", \"w+\")\n",
        "      f.write(ngrok_token+\",\"+ngrok_region)\n",
        "      f.close()\n",
        "    elif os.path.exists('/content/gdrive/MyDrive/WebUI/ngrokToken.txt'):\n",
        "      ngrok_token,ngrok_region = getoutput(\"cat /content/gdrive/MyDrive/WebUI/ngrokToken.txt\").split(\",\",2)\n",
        "    else:\n",
        "      print(\"warning: ngrok token not detected\")\n",
        "  commandline_arguments += ' --ngrok ' + ngrok_token + ' --ngrok-region ' + ngrok_region\n",
        "  commandline_arguments = commandline_arguments.replace(\"--share\",\"\")\n",
        "\n",
        "# Configs in drive\n",
        "if configs_in_drive:\n",
        "  config_dir = drive_config_dir+\"config.json\"\n",
        "  if not os.path.exists(drive_config_dir):\n",
        "    !mkdir -p {drive_config_dir}\n",
        "    !cp /content/sdw/styles.csv /content/sdw/ui-config.json /content/sdw/config.json {drive_config_dir}\n",
        "  commandline_arguments += ' --ui-config-file ' + drive_config_dir+\"ui-config.json\"\n",
        "  commandline_arguments += ' --ui-settings-file ' + drive_config_dir+\"config.json\"\n",
        "  commandline_arguments += ' --styles-file ' + drive_config_dir+\"styles.csv\"\n",
        "\n",
        "# Image outputs to drive (part 2)\n",
        "if output_to_drive:\n",
        "  !sed -i 's@\"outdir_txt2img_samples\": \"outputs/txt2img-images\"@\"outdir_txt2img_samples\": \"/content/gdrive/MyDrive/WebUI/outputs/txt2img-images\"@' {config_dir}\n",
        "  !sed -i 's@\"outdir_img2img_samples\": \"outputs/img2img-images\"@\"outdir_img2img_samples\": \"/content/gdrive/MyDrive/WebUI/outputs/img2img-images\"@' {config_dir}\n",
        "  !sed -i 's@\"outdir_extras_samples\": \"outputs/extras-images\"@\"outdir_extras_samples\": \"/content/gdrive/MyDrive/WebUI/outputs/extras-images\"@' {config_dir}\n",
        "  !sed -i 's@\"outdir_txt2img_grids\": \"outputs/txt2img-grids\"@\"outdir_txt2img_grids\": \"/content/gdrive/MyDrive/WebUI/outputs/txt2img-grids\"@' {config_dir}\n",
        "  !sed -i 's@\"outdir_img2img_grids\": \"outputs/img2img-grids\"@\"outdir_img2img_grids\": \"/content/gdrive/MyDrive/WebUI/outputs/img2img-grids\"@' {config_dir}\n",
        "  !sed -i 's@\"outdir_save\": \"log/images\"@\"outdir_save\": \"/content/gdrive/MyDrive/WebUI/outputs/log/images\"@' {config_dir}\n",
        "else:\n",
        "  if '/gdrive/' in getoutput('cat '+config_dir):\n",
        "    !sed -i 's@\"outdir_txt2img_samples\": \"outputs/txt2img-images\"@\"outdir_txt2img_samples\": \"outputs/txt2img-images\"@' {config_dir}\n",
        "    !sed -i 's@\"outdir_img2img_samples\": \"outputs/img2img-images\"@\"outdir_img2img_samples\": \"outputs/img2img-images\"@' {config_dir}\n",
        "    !sed -i 's@\"outdir_extras_samples\": \"outputs/extras-images\"@\"outdir_extras_samples\": \"outputs/extras-images\"@' {config_dir}\n",
        "    !sed -i 's@\"outdir_txt2img_grids\": \"outputs/txt2img-grids\"@\"outdir_txt2img_grids\": \"outputs/txt2img-grids\"@' {config_dir}\n",
        "    !sed -i 's@\"outdir_img2img_grids\": \"outputs/img2img-grids\"@\"outdir_img2img_grids\": \"outputs/img2img-grids\"@' {config_dir}\n",
        "    !sed -i 's@\"outdir_save\": \"log/images\"@\"outdir_save\": \"log/images\"@' {config_dir}\n",
        "\n",
        "\n",
        "# Install models from model_url, oh boi it's getting bigger\n",
        "extension_repo = []\n",
        "prefixes = [\n",
        "  \"config:\",\n",
        "  \"ui-config:\",\n",
        "  \"styles:\",\n",
        "  \"lora:\",\n",
        "  \"hypernetwork:\",\n",
        "  \"locon:\",\n",
        "  \"lycoris:\",\n",
        "  \"model:\",\n",
        "  \"vae:\",\n",
        "  \"control:\",\n",
        "  \"clone:\",\n",
        "  \"gfpgan:\",\n",
        "  \"ersgan:\",\n",
        "  \"swinr:\",\n",
        "  \"ldsr:\",\n",
        "  \"repo:\",\n",
        "  \"embeddings:\",\n",
        "  \"sam:\"\n",
        "]\n",
        "token = optional_huggingface_token if optional_huggingface_token else \"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\"\n",
        "user_header = f\"\\\"Authorization: Bearer {token}\\\"\"\n",
        "print('üì¶ Downloading models and stuff...', end='')\n",
        "def handle_manual(url):\n",
        "  if url.startswith(\"config:\"):\n",
        "    manual_download(url, \"/content/sdw/config.json\")\n",
        "  elif url.startswith(\"ui-config:\"):\n",
        "    manual_download(url, \"/content/sdw/ui-config.json\")\n",
        "  elif url.startswith(\"styles:\"):\n",
        "    manual_download(url, \"/content/sdw/styles.csv\")\n",
        "  elif url.startswith(\"sam:\"):\n",
        "    manual_download(url, sam_dir)\n",
        "  elif url.startswith(\"lora:\") or url.startswith(\"locon:\") or url.startswith(\"lycoris:\"):\n",
        "    manual_download(url, loras_dir)\n",
        "  elif url.startswith(\"hypernetwork:\"):\n",
        "    manual_download(url, hypernetworks_dir)\n",
        "  elif url.startswith(\"model:\"):\n",
        "    manual_download(url, models_dir)\n",
        "  elif url.startswith(\"vae:\"):\n",
        "    manual_download(url, vaes_dir)\n",
        "  elif url.startswith(\"control:\"):\n",
        "    manual_download(url, control_dir)\n",
        "  elif url.startswith(\"gfpgan:\"):\n",
        "    manual_download(url, \"/content/sdw/models/GFPGAN\")\n",
        "  elif url.startswith(\"esrgan:\"):\n",
        "    manual_download(url, \"/content/sdw/models/ESRGAN\")\n",
        "  elif url.startswith(\"swinr:\"):\n",
        "    manual_download(url, \"/content/sdw/models/SwinR\")\n",
        "  elif url.startswith(\"ldsr:\"):\n",
        "    manual_download(url, \"/content/sdw/models/LDSR\")\n",
        "  elif url.startswith(\"embeddings:\"):\n",
        "    manual_download(url, embeddings_dir)\n",
        "  elif url.startswith(\"extension:\"):\n",
        "    extension_repo.append(url)\n",
        "  elif url.startswith(\"clone:\") or url.startswith(\"repo:\"):\n",
        "    !cd /content/.downloaded && git clone $url\n",
        "\n",
        "def manual_download(url, dst):\n",
        "  url = url[url.find(':')+1:]\n",
        "  if \".json\" in url or \".csv\" in url:\n",
        "    !wget \"{url}\" -O {dst} -c\n",
        "  elif '.yaml' in url or '.yml' in url or 'discord' in url:\n",
        "    !wget \"{url}\" -P {dst} -c\n",
        "  elif 'drive.google' in url:\n",
        "    if 'folders' in url:\n",
        "      !gdown --folder \"{url}\" -O {dst} --fuzzy -c\n",
        "    else:\n",
        "      !gdown \"{url}\" -O {dst} --fuzzy -c\n",
        "  elif 'huggingface' in url:\n",
        "    if '/blob/' in url:\n",
        "      url = url.replace('/blob/', '/resolve/')\n",
        "    parsed_link = '\\n{}\\n\\tout={}'.format(url,unquote(url.split('/')[-1]))\n",
        "    !echo -e \"{parsed_link}\" | aria2c --header={user_header} --console-log-level=error --summary-interval=10 -i- -j5 -x16 -s16 -k1M -c -d \"{dst}\"\n",
        "  elif 'http' in url or 'magnet' in url:\n",
        "    parsed_link = '\"{}\"'.format(url)\n",
        "    !aria2c --optimize-concurrent-downloads --console-log-level=error --summary-interval=10 -j5 -x16 -s16 -k1M -c -d {dst} -Z {parsed_link}\n",
        "\n",
        "def download(url):\n",
        "  try:\n",
        "    have_drive_link\n",
        "  except:\n",
        "    if \"drive.google.com\" in url:\n",
        "      # I'm sorry drive ID enjoyer, this will make ID useless :(\n",
        "      !pip install -U gdown\n",
        "      have_drive_link = True\n",
        "  links_and_paths = url.split(',')\n",
        "  !mkdir -p {destination_dir} {models_dir} {vaes_dir} {hypernetworks_dir} {embeddings_dir} {loras_dir} {sam_dir}\n",
        "  http_links = []\n",
        "  huggingface_links = []\n",
        "  for link_or_path in links_and_paths:\n",
        "    link_or_path = link_or_path.strip()\n",
        "    if not link_or_path:\n",
        "      continue\n",
        "\n",
        "    if any(link_or_path.startswith(prefix.lower()) for prefix in prefixes):\n",
        "      handle_manual(link_or_path)\n",
        "      continue\n",
        "\n",
        "    if 'github.com' in link_or_path and ( '.git' in link_or_path or not '.' in link_or_path.split('/')[-1] ):\n",
        "      extension_repo.append(link_or_path)\n",
        "      continue\n",
        "\n",
        "    if '.yaml' in link_or_path or '.yml' in link_or_path or 'discord' in link_or_path:\n",
        "      !wget {link_or_path} -P {destination_dir} -c\n",
        "    elif 'drive.google' in link_or_path:\n",
        "      if 'folders' in link_or_path:\n",
        "        !gdown --folder {link_or_path} -O {destination_dir} --fuzzy -c\n",
        "      else:\n",
        "        !gdown {link_or_path} -O {destination_dir} --fuzzy -c\n",
        "    elif 'huggingface' in link_or_path:\n",
        "      if '/blob/' in link_or_path:\n",
        "        link_or_path = link_or_path.replace('/blob/', '/resolve/')\n",
        "      huggingface_links.append(link_or_path)\n",
        "    elif 'http' in link_or_path or 'magnet' in link_or_path:\n",
        "      http_links.append(link_or_path)\n",
        "    elif '/' in link_or_path:\n",
        "      if not os.path.exists('/content/gdrive/MyDrive'):\n",
        "        print('Looks like there\\'s a path in your url. You need to mount your drive first.')\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/gdrive')\n",
        "      !rsync -avr --progress /content/gdrive/MyDrive/{link_or_path} {destination_dir}\n",
        "    else:\n",
        "      !gdown {link_or_path} -O {destination_dir} --fuzzy -c\n",
        "  if http_links:\n",
        "    links_string = ' '.join(['\"{}\"'.format(x) for x in http_links])\n",
        "    !aria2c --optimize-concurrent-downloads --console-log-level=error --summary-interval=10 -j5 -x16 -s16 -k1M -c -d {destination_dir}  -Z {links_string}\n",
        "    del links_string\n",
        "  if huggingface_links:\n",
        "    # links_string = ' '.join(['\"{}\"'.format(x) for x in huggingface_links])\n",
        "    # !aria2c --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {destination_dir} -Z {links_string}\n",
        "    # for link in huggingface_links:\n",
        "    #   !aria2c --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {destination_dir} -o {link.split('/')[-1]} {link}\n",
        "    links_string = '\\n'.join(['{}\\n\\tout={}'.format(x,unquote(x.split('/')[-1])) for x in huggingface_links])\n",
        "    !echo -e \"{links_string}\" | aria2c --header={user_header} --optimize-concurrent-downloads --console-log-level=error --summary-interval=10 -i- -j5 -x16 -s16 -k1M -c -d {destination_dir}\n",
        "\n",
        "if verbose_download:\n",
        "  download(model_url)\n",
        "else:\n",
        "  with capture.capture_output() as cap:\n",
        "    download(model_url)\n",
        "    del cap\n",
        "\n",
        "print('\\rüèÅ Download finished.', flush=True)\n",
        "\n",
        "if len(extension_repo) > 0:\n",
        "  print('‚ú® Installing custom extensions...', end='')\n",
        "  with capture.capture_output() as cap:\n",
        "    for repo in extension_repo:\n",
        "      repo_name = repo.split('/')[-1]\n",
        "      !cd {extensions_dir} \\\n",
        "        && git clone \"{repo}\" \\\n",
        "        && cd {repo_name} \\\n",
        "        && git fetch\n",
        "  print('\\rüèÅ Installed',len(extension_repo),'custom extensions.', flush=True)\n",
        "\n",
        "print('\\n')\n",
        "# Link all files by filtering accoridng to their type\n",
        "with capture.capture_output() as cap:\n",
        "  # files = os.listdir(destination_dir)\n",
        "  files = [os.path.join(dp,f) for dp, dn, fn in os.walk(destination_dir) for f in fn] # Thanks Aojiru!\n",
        "  for file in files:\n",
        "    name, file_extension = os.path.splitext(file)\n",
        "    if '.aria2' in file:\n",
        "      continue\n",
        "    file_path = os.path.join(destination_dir, file)\n",
        "    file_size = os.path.getsize(file_path)\n",
        "    if \"sam_\" in name and file_extension == \".pth\":\n",
        "      !ln \"{file_path}\" {sam_dir}\n",
        "    elif \"control_\" in name or \"t2iadapter_\" in name or file_extension == \".pth\":\n",
        "      !ln \"{file_path}\" {control_dir}\n",
        "    elif file_extension in ['.yaml', '.yml'] or file_size > 1_500_000_000:\n",
        "      !ln \"{file_path}\" {models_dir}\n",
        "    elif \"kl-f8\" in name or \"vae_\" in file or \"vae.\" in file or \"vae-\" in file or file_size > 380_000_000:\n",
        "      !ln \"{file_path}\" {vaes_dir}\n",
        "    elif getoutput('if rg -q -o \"lora_unet\" \"'+file_path+'\"; then echo 1; else echo 0; fi') == \"1\":\n",
        "      !ln \"{file_path}\" {loras_dir}\n",
        "    elif (file_extension == '.pt' or file_extension == '.safetensors') and file_size < 10_000_000:\n",
        "      !ln \"{file_path}\" {embeddings_dir}\n",
        "    else:\n",
        "      !ln \"{file_path}\" {hypernetworks_dir}\n",
        "  del cap\n",
        "\n",
        "# Automatically loads vae for first run, if it exists.\n",
        "if auto_vae:\n",
        "  if '.vae.pt' in os.listdir(vaes_dir) or '/vae' in model_url:\n",
        "    commandline_arguments+=' --vae-path $(readlink -f $(find '+vaes_dir+' \\( -name \"*.vae.pt\" -or -name \"*.ckpt\" \\) -print -quit))'\n",
        "\n",
        "# Configure Alternatives Tunnels (Colab native, localtunnel, cloudflared, bore with auth)\n",
        "if alternative_tunnels:\n",
        "  commandline_arguments = commandline_arguments.replace(\"--share\",\"\")\n",
        "  commandline_arguments += \" --multiple\"\n",
        "  print(\"‚åö \\033[95m\\033[1mGenerating alternative tunnels...\", end='')\n",
        "  with capture.capture_output() as cap:\n",
        "    %cd /content\n",
        "    if not os.path.exists('/tools/node/bin/lt'):\n",
        "      !npm install -g localtunnel\n",
        "    if not os.path.exists('/usr/bin/cloudflared'):\n",
        "      !curl -Lo /usr/bin/cloudflared https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 && chmod +x /usr/bin/cloudflared\n",
        "    del cap\n",
        "  !true > /content/nohup.out\n",
        "  !nohup lt --port 7860 > /content/nohup.out 2>&1 &\n",
        "  !nohup cloudflared tunnel --url localhost:7860 > /content/nohup.out 2>&1 &\n",
        "  if with_bore:\n",
        "    if not os.path.exists('/usr/bin/bore'):\n",
        "      !curl -Ls https://github.com/ekzhang/bore/releases/download/v0.4.0/bore-v0.4.0-x86_64-unknown-linux-musl.tar.gz | tar zx -C /usr/bin\n",
        "    !nohup bore local 7860 --to bore.pub > /content/nohup.out 2>&1 &\n",
        "    if not \"--gradio-auth\" in commandline_arguments:\n",
        "      import random\n",
        "      import string\n",
        "      gradio_password = ''.join(random.choice(string.ascii_lowercase) for i in range(5))\n",
        "      commandline_arguments+=\" --gradio-auth {}:{}\".format(\"ncpt\", gradio_password)\n",
        "    else:\n",
        "      gradio_password = False\n",
        "  !sleep 4\n",
        "  print(\"\\rüí° \\033[95m\\033[1mUse one of these alternative tunnels after the loading is finished: \", flush=True)\n",
        "  from google.colab.output import serve_kernel_port_as_window\n",
        "  # serve_kernel_port_as_window(7860, anchor_text=\"https://th15f4k3l1nkofcn0tr34ll0l-7860-colab.googleusercontent.com/\")\n",
        "  !cat /content/nohup.out | rg -a -o \"https[^ ]*.*\\.trycloudflare\\.com|https[^ ]*.*\\.loca\\.lt|bore.pub:[^ ]*\" | sed 's@bore.pub@http://bore.pub@'\n",
        "  print(\"\\n\")\n",
        "  if with_bore:\n",
        "    if gradio_password:\n",
        "      print(\"\\rüîê \\033[0m\\033[1mLooks like you're using bore without --gradio-auth huh... \")\n",
        "      print(\"For security, I've enforced to use gradio auth, so use this account to login:\")\n",
        "      print(\"üëâ‚ö†Ô∏è Username: ncpt\")\n",
        "      print(\"üëâ‚ö†Ô∏è Password:\", gradio_password,\"\\n\\n\")\n",
        "\n",
        "# If no xformers installed, remove --xformers from arg to avoid using old builtin xformers\n",
        "# if not os.path.exists(\"/usr/local/lib/python3.10/dist-packages/xformers\"):\n",
        "#   commandline_arguments = commandline_arguments.replace(\"--xformers\",\"\")\n",
        "\n",
        "# Krita extension support (adding --api automatically) + toggleable.\n",
        "with capture.capture_output() as cap:\n",
        "  if krita_paint_ext:\n",
        "    # Add api if no api (if lazy y'know)\n",
        "    if not \"--api\" in commandline_arguments:\n",
        "      commandline_arguments+=\" --api\"\n",
        "    %cd /content/sdw\n",
        "    if os.path.exists('/content/sdw/extensions/auto-sd-paint-ext'):\n",
        "      !cd ./extensions/auto-sd-paint-ext && git fetch && git merge # Deflecting FETCH_HEAD not found bug\n",
        "    else:\n",
        "      !git clone https://github.com/ashen-sensored/auto-sd-paint-ext extensions/auto-sd-paint-ext\n",
        "  else:\n",
        "    if os.path.exists('/content/sdw/extensions/auto-sd-paint-ext'):\n",
        "      !rm -rf /content/sdw/extensions/auto-sd-paint-ext\n",
        "  # Remove junks\n",
        "  !find /content/sdw/ -name \".ipynb_checkpoints\" -type d -exec rm -r {} \\;\n",
        "\n",
        "\n",
        "# Print all files in every important directory\n",
        "print(\"\\033[96mCan't see your files in here? Activate verbose_download to debug!\\n\")\n",
        "print(\"\\033[92m\\033[1m‚ï≠-üì¶ Models + Configs\\033[96m\")\n",
        "!find {models_dir}/ -mindepth 1 ! -name '*.txt' -printf '%f\\n'\n",
        "print(\"\\n\\033[92m\\033[1m‚ï≠-üì¶ VAEs\\033[96m\")\n",
        "!find {vaes_dir}/ -mindepth 1 ! -name '*.txt' -printf '%f\\n'\n",
        "print(\"\\n\\033[92m\\033[1m‚ï≠-üì¶ Custom Embeddings (inbuilt is hidden)\\033[96m\")\n",
        "!find {embeddings_dir}/ -mindepth 1 -maxdepth 1 -name '*.pt' -or -name '*.safetensors' -printf '%f\\n'\n",
        "print(\"\\n\\033[92m\\033[1m‚ï≠-üì¶ LoRAs\\033[96m\")\n",
        "!find {loras_dir}/ -mindepth 1 ! -name '*.keep' -printf '%f\\n'\n",
        "# print(\"\\n\\033[92m\\033[1m‚ï≠-üì¶ LyCORIS\\033[96m\")\n",
        "# !find {lycoris_dir}/ -mindepth 1 ! -name '*.keep' -printf '%f\\n'\n",
        "print(\"\\n\\033[92m\\033[1m‚ï≠-üì¶ Hypernetworks\\033[96m\")\n",
        "!find {hypernetworks_dir}/ -mindepth 1 ! -name '*.txt' -printf '%f\\n'\n",
        "print(\"\\n\\033[92m\\033[1m‚ï≠-üì¶ Extensions\\033[96m\")\n",
        "!find {extensions_dir}/ -mindepth 1 -maxdepth 1 ! -name '*.txt' -printf '%f\\n'\n",
        "print(\"\\n\\n\\033[0m\")\n",
        "\n",
        "# HF OUT support!\n",
        "if optional_huggingface_token:\n",
        "  commandline_arguments+=\" --hf-token-out \"+optional_huggingface_token\n",
        "\n",
        "# Start the weebui\n",
        "%cd /content/sdw\n",
        "\n",
        "if null_model:\n",
        "  print(\"\\033[91m ‚ö†Ô∏è Null model will be loaded, if you don't understand please uncheck the model \\033[0m\")\n",
        "  !wget https://huggingface.co/ckpt/null/resolve/main/nullModelzeros.ckpt -P {models_dir} -c\n",
        "  commandline_arguments+=\" --ckpt \"+models_dir+\"/nullModelzeros.ckpt \"\n",
        "\n",
        "if fast_start:\n",
        "  # commandline_arguments += \" --skip-install\"\n",
        "  print(\"\\033[91m ‚ö†Ô∏è Fast start is active, please disable it if you have any problem! \\033[0m\")\n",
        "  !python webui.py $commandline_arguments\n",
        "else:\n",
        "  !pip uninstall torch torchaudio pytorch -y\n",
        "  !COMMANDLINE_ARGS=\"{commandline_arguments} --api\" REQS_FILE=\"requirements_versions.txt\" python launch.py\n",
        "time_since_start = timedelta(seconds=time.time()-start_colab)\n",
        "print(\"\\n\\n\\033[96m‚åö You've been running this colab for\",\"%02d:%02d:%02d\" % (time_since_start.seconds / 3600, (time_since_start.seconds / 60) % 60, time_since_start.seconds % 60))\n",
        "print(\"\\n\\n\")"
      ]
    }
  ]
}